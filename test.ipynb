{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please note that `empty_sequence` uses the KL divergence with Barnes-Hut approximation (angle=0.5) by default.\n",
      "Loading data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 25\u001b[0m dataX, dataLabels, D, V, _ \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_home\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_home\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_return\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_labels_D_V\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhd_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mperplexity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mperp\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknn_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhnswlib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# we use an approximation of high-dimensional neighbors to speed up computations\u001b[39;49;00m\n\u001b[0;32m     33\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     37\u001b[0m execution_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Git\\hyperbolic-tsne\\hyperbolicTSNE\\data_loaders.py:435\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(dataset, data_home, to_return, pca_components, knn_method, metric, n_neighbors, knn_params, hd_method, hd_params, sample, random_state, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Data Loader] Input matrix X is dense ... using dense PCA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    434\u001b[0m             pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39mpca_components, svd_solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)  \u001b[38;5;66;03m# remember random state\u001b[39;00m\n\u001b[1;32m--> 435\u001b[0m             X \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    439\u001b[0m to_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels_X_D_V\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m to_return \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m to_return\n",
      "File \u001b[1;32mc:\\Users\\Milan\\miniconda3\\envs\\htsne\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Milan\\miniconda3\\envs\\htsne\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:462\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;124;03mC-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 462\u001b[0m U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhiten:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Milan\\miniconda3\\envs\\htsne\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:514\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_full(X, n_components)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_truncated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_svd_solver\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Milan\\miniconda3\\envs\\htsne\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:618\u001b[0m, in \u001b[0;36mPCA._fit_truncated\u001b[1;34m(self, X, n_components, svd_solver)\u001b[0m\n\u001b[0;32m    614\u001b[0m     U, Vt \u001b[38;5;241m=\u001b[39m svd_flip(U[:, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], Vt[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# sign flipping is done inside\u001b[39;00m\n\u001b[1;32m--> 618\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[43mrandomized_svd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_oversamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_oversamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterated_power\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpower_iteration_normalizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower_iteration_normalizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflip_sign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_ \u001b[38;5;241m=\u001b[39m n_samples\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_ \u001b[38;5;241m=\u001b[39m Vt\n",
      "File \u001b[1;32mc:\\Users\\Milan\\miniconda3\\envs\\htsne\\lib\\site-packages\\sklearn\\utils\\extmath.py:446\u001b[0m, in \u001b[0;36mrandomized_svd\u001b[1;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state, svd_lapack_driver)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transpose:\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;66;03m# this implementation is a bit faster with smaller shape[1]\u001b[39;00m\n\u001b[0;32m    444\u001b[0m     M \u001b[38;5;241m=\u001b[39m M\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m--> 446\u001b[0m Q \u001b[38;5;241m=\u001b[39m \u001b[43mrandomized_range_finder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpower_iteration_normalizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower_iteration_normalizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# project M to the (k + p) dimensional space using the basis vectors\u001b[39;00m\n\u001b[0;32m    455\u001b[0m B \u001b[38;5;241m=\u001b[39m safe_sparse_dot(Q\u001b[38;5;241m.\u001b[39mT, M)\n",
      "File \u001b[1;32mc:\\Users\\Milan\\miniconda3\\envs\\htsne\\lib\\site-packages\\sklearn\\utils\\extmath.py:282\u001b[0m, in \u001b[0;36mrandomized_range_finder\u001b[1;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[0;32m    278\u001b[0m         Q, _ \u001b[38;5;241m=\u001b[39m linalg\u001b[38;5;241m.\u001b[39mqr(safe_sparse_dot(A\u001b[38;5;241m.\u001b[39mT, Q), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meconomic\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# Sample the range of A using by linear projection of Q\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# Extract an orthonormal basis\u001b[39;00m\n\u001b[1;32m--> 282\u001b[0m Q, _ \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqr\u001b[49m\u001b[43m(\u001b[49m\u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meconomic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Q\n",
      "File \u001b[1;32mc:\\Users\\Milan\\miniconda3\\envs\\htsne\\lib\\site-packages\\scipy\\linalg\\_decomp_qr.py:142\u001b[0m, in \u001b[0;36mqr\u001b[1;34m(a, overwrite_a, lwork, mode, pivoting, check_finite)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     geqrf, \u001b[38;5;241m=\u001b[39m get_lapack_funcs((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeqrf\u001b[39m\u001b[38;5;124m'\u001b[39m,), (a1,))\n\u001b[1;32m--> 142\u001b[0m     qr, tau \u001b[38;5;241m=\u001b[39m \u001b[43msafecall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeqrf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeqrf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meconomic\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m M \u001b[38;5;241m<\u001b[39m N:\n\u001b[0;32m    146\u001b[0m     R \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mtriu(qr)\n",
      "File \u001b[1;32mc:\\Users\\Milan\\miniconda3\\envs\\htsne\\lib\\site-packages\\scipy\\linalg\\_decomp_qr.py:19\u001b[0m, in \u001b[0;36msafecall\u001b[1;34m(f, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m     17\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     18\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlwork\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ret[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreal\u001b[38;5;241m.\u001b[39mastype(numpy\u001b[38;5;241m.\u001b[39mint_)\n\u001b[1;32m---> 19\u001b[0m ret \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124millegal value in \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mth argument of internal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m                      \u001b[38;5;241m%\u001b[39m (\u001b[38;5;241m-\u001b[39mret[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], name))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import traceback\n",
    "import numpy as np\n",
    "import time\n",
    "#from cuda import cuda, nvrtc\n",
    "\n",
    "from hyperbolicTSNE.util import find_last_embedding\n",
    "from hyperbolicTSNE.visualization import plot_poincare, animate\n",
    "from hyperbolicTSNE import load_data, Datasets, SequentialOptimizer, initialization, HyperbolicTSNE\n",
    "\n",
    "data_home = \"datasets\"\n",
    "log_path = \"temp/poincaregpu/\"  # path for saving embedding snapshots\n",
    "\n",
    "only_animate = False\n",
    "seed = 42\n",
    "dataset = Datasets.MNIST  # the Datasets handler provides access to several data sets used throughout the repository\n",
    "num_points = 70000  # we use a subset for demonstration purposes, full MNIST has N=70000\n",
    "perp = 15  # we use a perplexity of 30 in this example\n",
    "logging = False\n",
    "\n",
    "print(\"Loading data\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "dataX, dataLabels, D, V, _ = load_data(\n",
    "    dataset, \n",
    "    data_home=data_home, \n",
    "    random_state=seed, \n",
    "    to_return=\"X_labels_D_V\",\n",
    "    hd_params={\"perplexity\": perp}, \n",
    "    sample=num_points, \n",
    "    knn_method=\"hnswlib\"  # we use an approximation of high-dimensional neighbors to speed up computations\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Data loading:\", execution_time, \"seconds\")\n",
    "\n",
    "exaggeration_factor = 12  # Just like regular t-SNE, we use early exaggeration with a factor of 12\n",
    "learning_rate = (dataX.shape[0] * 1) / (exaggeration_factor * 1000)  # We adjust the learning rate to the hyperbolic setting\n",
    "ex_iterations = 250  # The embedder is to execute 250 iterations of early exaggeration, ...\n",
    "main_iterations = 750  # ... followed by 750 iterations of non-exaggerated gradient descent.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============= RUNNING EXACT GPU =============\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "opt_config = dict(\n",
    "    learning_rate_ex=learning_rate,  # learning rate during exaggeration\n",
    "    learning_rate_main=learning_rate,  # learning rate main optimization \n",
    "    exaggeration=exaggeration_factor, \n",
    "    exaggeration_its=ex_iterations, \n",
    "    gradientDescent_its=main_iterations, \n",
    "    vanilla=False,  # if vanilla is set to true, regular gradient descent without any modifications is performed; for  vanilla set to false, the optimization makes use of momentum and gains\n",
    "    momentum_ex=0.5,  # Set momentum during early exaggeration to 0.5\n",
    "    momentum=0.8,  # Set momentum during non-exaggerated gradient descent to 0.8\n",
    "    exact=False,  # To use the quad tree for acceleration (like Barnes-Hut in the Euclidean setting) or to evaluate the gradient exactly\n",
    "    area_split=False,  # To build or not build the polar quad tree based on equal area splitting or - alternatively - on equal length splitting\n",
    "    n_iter_check=10,  # Needed for early stopping criterion\n",
    "    size_tol=0.999  # Size of the embedding to be used as early stopping criterion\n",
    ")\n",
    "\n",
    "opt_params = SequentialOptimizer.sequence_poincare(**opt_config)\n",
    "\n",
    "print(\"Sequence defined\")\n",
    "\n",
    "# Start: configure logging\n",
    "if logging:\n",
    "    logging_dict = {\n",
    "        \"log_path\": log_path\n",
    "    }\n",
    "    opt_params[\"logging_dict\"] = logging_dict\n",
    "\n",
    "    log_path = opt_params[\"logging_dict\"][\"log_path\"]\n",
    "    # Delete old log path\n",
    "    if os.path.exists(log_path) and not only_animate:\n",
    "        import shutil\n",
    "        shutil.rmtree(log_path)\n",
    "# End: logging\n",
    "\n",
    "# Compute an initial embedding of the data via PCA\n",
    "X_embedded = initialization(\n",
    "    n_samples=dataX.shape[0],\n",
    "    n_components=2,\n",
    "    X=dataX,\n",
    "    random_state=seed,\n",
    "    method=\"pca\"\n",
    ")\n",
    "print(X_embedded)\n",
    "\n",
    "# Initialize the embedder\n",
    "htsne = HyperbolicTSNE(\n",
    "    init=X_embedded, \n",
    "    n_components=2, \n",
    "    metric=\"precomputed\", \n",
    "    verbose=True, \n",
    "    opt_method=SequentialOptimizer, \n",
    "    opt_params=opt_params\n",
    ")\n",
    "\n",
    "X_embedded = initialization(\n",
    "    n_samples=dataX.shape[0],\n",
    "    n_components=2,\n",
    "    X=dataX,\n",
    "    random_state=seed,\n",
    "    method=\"pca\"\n",
    ")\n",
    "print(X_embedded)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    hyperbolicEmbedding = htsne.fit_transform((D, V))\n",
    "except ValueError:\n",
    "    print(\"Error!\")\n",
    "    hyperbolicEmbedding = find_last_embedding(log_path)\n",
    "    traceback.print_exc()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time:\", execution_time, \"seconds\")\n",
    "\n",
    "# Create a rendering of the embedding and save it to a file\n",
    "if not os.path.exists(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "fig = plot_poincare(hyperbolicEmbedding, dataLabels)\n",
    "fig.show()\n",
    "fig.savefig(f\"results/{dataset.name}-inexact.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============= RUNNING EXACT CPU =============\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "opt_config = dict(\n",
    "    learning_rate_ex=learning_rate,  # learning rate during exaggeration\n",
    "    learning_rate_main=learning_rate,  # learning rate main optimization \n",
    "    exaggeration=exaggeration_factor, \n",
    "    exaggeration_its=ex_iterations, \n",
    "    gradientDescent_its=main_iterations, \n",
    "    vanilla=False,  # if vanilla is set to true, regular gradient descent without any modifications is performed; for  vanilla set to false, the optimization makes use of momentum and gains\n",
    "    momentum_ex=0.5,  # Set momentum during early exaggeration to 0.5\n",
    "    momentum=0.8,  # Set momentum during non-exaggerated gradient descent to 0.8\n",
    "    exact=True,  # To use the quad tree for acceleration (like Barnes-Hut in the Euclidean setting) or to evaluate the gradient exactly\n",
    "    area_split=False,  # To build or not build the polar quad tree based on equal area splitting or - alternatively - on equal length splitting\n",
    "    n_iter_check=10,  # Needed for early stopping criterion\n",
    "    size_tol=0.999  # Size of the embedding to be used as early stopping criterion\n",
    ")\n",
    "\n",
    "opt_params = SequentialOptimizer.sequence_poincare(**opt_config)\n",
    "\n",
    "print(\"Sequence defined\")\n",
    "\n",
    "if logging:\n",
    "    log_path = \"temp/poincarecpu/\"  # path for saving embedding snapshots\n",
    "\n",
    "    # Start: configure logging\n",
    "    logging_dict = {\n",
    "        \"log_path\": log_path\n",
    "    }\n",
    "    #opt_params[\"logging_dict\"] = logging_dict\n",
    "\n",
    "    log_path = opt_params[\"logging_dict\"][\"log_path\"]\n",
    "    # Delete old log path\n",
    "    if os.path.exists(log_path) and not only_animate:\n",
    "        import shutil\n",
    "        shutil.rmtree(log_path)\n",
    "# End: logging\n",
    "\n",
    "# Compute an initial embedding of the data via PCA\n",
    "X_embedded = initialization(\n",
    "    n_samples=dataX.shape[0],\n",
    "    n_components=2,\n",
    "    X=dataX,\n",
    "    random_state=seed,\n",
    "    method=\"pca\"\n",
    ")\n",
    "\n",
    "# Initialize the embedder\n",
    "htsne = HyperbolicTSNE(\n",
    "    init=X_embedded, \n",
    "    n_components=2, \n",
    "    metric=\"precomputed\", \n",
    "    verbose=True, \n",
    "    opt_method=SequentialOptimizer, \n",
    "    opt_params=opt_params\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    #hyperbolicEmbedding = htsne.fit_transform((D, V))\n",
    "    print(\"would run exact\")\n",
    "except ValueError:\n",
    "    print(\"Error!\")\n",
    "    hyperbolicEmbedding = find_last_embedding(log_path)\n",
    "    traceback.print_exc()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time:\", execution_time, \"seconds\")\n",
    "\n",
    "# Create a rendering of the embedding and save it to a file\n",
    "if not os.path.exists(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "fig = plot_poincare(hyperbolicEmbedding, dataLabels)\n",
    "fig.show()\n",
    "fig.savefig(f\"results/{dataset.name}-exact.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htsne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
